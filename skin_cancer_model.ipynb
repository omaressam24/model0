{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "KMHSLaDj4yF-",
    "outputId": "731624e8-7a42-4054-d466-cc54b6543a48"
   },
   "outputs": [],
   "source": [
    "!pip install tf-nightly-gpu-2.0-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "420fWukjxKPp",
    "outputId": "b2ce0715-9c74-4b53-d491-ba9da3cc66d3"
   },
   "outputs": [],
   "source": [
    "# Mount the drive in order to get access to the data \n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1707208
    },
    "colab_type": "code",
    "id": "ctkN-lruyCz5",
    "outputId": "12126ac4-a022-4b26-95c5-eaedf776d984"
   },
   "outputs": [],
   "source": [
    "# Untar the data we have stored in our drive\n",
    "!tar -zxf /content/gdrive/My\\ Drive/skin_cancer_data/data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0aAiZ6zzi67"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.applications import resnet50, mobilenet, mobilenet_v2, vgg16, inception_v3\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Reshape\n",
    "from tensorflow.keras.layers import Input, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTj73Pud0dnM"
   },
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=1234\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6O0KpYw0haK"
   },
   "outputs": [],
   "source": [
    "# Get the path to train and validation directories\n",
    "train_data_path = Path(\"data/train/\")\n",
    "valid_data_path = Path(\"data/valid/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 792
    },
    "colab_type": "code",
    "id": "Fz8yd76X0mYT",
    "outputId": "ff925470-55ce-4d14-efe3-2d2b548870a7"
   },
   "outputs": [],
   "source": [
    "# simple visualization\n",
    "sample_images = []\n",
    "\n",
    "# get all subdirs\n",
    "subdirs = sorted(os.listdir(train_data_path))\n",
    "subdirs = [x for x in subdirs if \"DS_Store\" not in x]\n",
    "\n",
    "# get samples\n",
    "for subdir in subdirs:\n",
    "    images = os.listdir(train_data_path / subdir)\n",
    "    images = [x for x in images if \"DS_Store\" not in x]\n",
    "    random_images_idx = np.random.choice(len(images), 5)\n",
    "    for idx in random_images_idx:\n",
    "        img = imread(train_data_path/ subdir / images[idx])\n",
    "        sample_images.append(img)\n",
    "\n",
    "# plot samples\n",
    "f,ax = plt.subplots(7, 5, figsize=(10,10))\n",
    "\n",
    "for i, img in enumerate(sample_images):\n",
    "    ax[i//5, i%5].imshow(img)\n",
    "    ax[i//5, i%5].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UIHyQhr0pw7"
   },
   "outputs": [],
   "source": [
    "# some constants\n",
    "img_height, img_width, img_channels = 224,224,3\n",
    "batch_size = 64\n",
    "nb_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_fatH-UE0uZy",
    "outputId": "363f5c72-830e-434e-9dc5-59a8d9b565ef"
   },
   "outputs": [],
   "source": [
    "# Get a generator \n",
    "data_gen = ImageDataGenerator(preprocessing_function=mobilenet_v2.preprocess_input)\n",
    "\n",
    "# Make data generator for training and validation data\n",
    "train_data_gen = data_gen.flow_from_directory(train_data_path, \n",
    "                                              target_size=(img_height, img_width), \n",
    "                                              class_mode=\"categorical\", \n",
    "                                              shuffle=True, \n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "valid_data_gen = data_gen.flow_from_directory(valid_data_path, \n",
    "                                              target_size=(img_height, img_width), \n",
    "                                              class_mode=\"categorical\", \n",
    "                                              shuffle=False, \n",
    "                                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "nn0K4rgm0yfy",
    "outputId": "302af985-592c-4fef-fc46-7b6aaf5548e3"
   },
   "outputs": [],
   "source": [
    "# prepare validation data \n",
    "valid_images, valid_labels = [], []\n",
    "class_indices = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "\n",
    "subdirs = sorted(os.listdir(valid_data_path))\n",
    "subdirs = [x for x in subdirs if \"DS_Store\" not in x]\n",
    "\n",
    "for subdir in subdirs:\n",
    "  print(f\"Processing {subdir}\")\n",
    "  images = os.listdir(valid_data_path / subdir)\n",
    "  images = [x for x in images if \"DS_Store\" not in x]\n",
    "  print(\"Number of images found: \", len(images))\n",
    "  \n",
    "  for img in images:\n",
    "    img = imread(valid_data_path / subdir / img)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    label = class_indices[subdir]\n",
    "    valid_images.append(img)\n",
    "    valid_labels.append(label)\n",
    "  print(\"=\"*50)\n",
    "  \n",
    "valid_images = np.array(valid_images, dtype=np.float32)\n",
    "valid_images = mobilenet_v2.preprocess_input(valid_images)\n",
    "valid_labels = np.array(valid_labels)\n",
    "valid_labels_cat = to_categorical(valid_labels, num_classes=7)\n",
    "print(\"\\n\", valid_images.shape, valid_labels.shape, valid_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOmRJcR2cVGc"
   },
   "outputs": [],
   "source": [
    "# # compute class weights\n",
    "# training_labels_count = []\n",
    "\n",
    "# subdirs = sorted(os.listdir(train_data_path))\n",
    "# subdirs = [x for x in subdirs if \"DS_Store\" not in x]\n",
    "\n",
    "# for subdir in subdirs:\n",
    "#   print(f\"Processing {subdir}\")\n",
    "#   images = os.listdir(train_data_path / subdir)\n",
    "#   images = [x for x in images if \"DS_Store\" not in x]\n",
    "#   print(\"Number of images found: \", len(images))\n",
    "#   labels = [class_indices[subdir]]*len(images)\n",
    "#   training_labels_count +=labels\n",
    "\n",
    "# training_labels_count = np.array(training_labels_count)\n",
    "# print(training_labels_count.shape)\n",
    "\n",
    "# class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "#                                      classes=np.unique(training_labels_count), \n",
    "#                                      y=training_labels_count)\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEkcaK9jvLJY"
   },
   "outputs": [],
   "source": [
    "# Make class weights much simpler\n",
    "class_weights = {0:1.0, 1:1.0, 2:1.0, 3:3.0, 4: 1.5, 5:1.0, 6:1.0, 7:2.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqIxW-1WHx1n"
   },
   "outputs": [],
   "source": [
    "# Get fine-tuning/transfer-learning model\n",
    "def get_fine_tuning_model(base_model, top_model, inputs, learning_type):\n",
    "    if learning_type=='transfer_learning':\n",
    "        print(\"Doing transfer learning\")\n",
    "        K.set_learning_phase(0)\n",
    "        base_model.trainable = False\n",
    "        features = base_model(inputs)\n",
    "        outputs = top_model(features)\n",
    "    else:\n",
    "        print(\"Doing fine-tuning\")\n",
    "        features = base_model(inputs)\n",
    "        outputs = top_model(features)\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "P4NWwk7d02D6",
    "outputId": "5d6b50d4-9896-43bc-f49f-05a2ae8c0976"
   },
   "outputs": [],
   "source": [
    "# Use MobileNets family models as we have to deploy this on a mobile in the end\n",
    "base_model = mobilenet_v2.MobileNetV2(input_shape=(img_height, img_width, img_channels),\n",
    "                                 include_top=False, \n",
    "                                 weights='imagenet',\n",
    "                                 pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "NaGj9m2pIDDP",
    "outputId": "dda58279-850f-4161-bc56-00d56cd8be51"
   },
   "outputs": [],
   "source": [
    "# Define a top model: extra layers that we are going to add on \n",
    "# top of our base network\n",
    "feature_inputs = Input(shape=base_model.output_shape, name='top_model_input')\n",
    "x = Reshape((1,1,1280), name='reshape_1')(feature_inputs)\n",
    "x = Dropout(0.5,name='drop')(x)\n",
    "x = Conv2D(7, (1,1), name=\"last_conv\", \n",
    "           kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "x = Activation(activation=\"softmax\", name=\"ouputs\")(x)\n",
    "outputs = Reshape((7,), name=\"reshape_2\")(x)\n",
    "\n",
    "# define the  model\n",
    "top_model = Model(feature_inputs, outputs, name='top_model')\n",
    "\n",
    "\n",
    "# get model for tranfser learning\n",
    "inputs = Input(shape=(img_height, img_width, img_channels))\n",
    "model = get_fine_tuning_model(base_model, top_model, inputs, \"transfer_learning\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qESXDcKJ0_6A"
   },
   "outputs": [],
   "source": [
    "# We need top 2 predictions in our case\n",
    "def top_2(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true=y_true, y_pred=y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaabwMUR1EQo"
   },
   "outputs": [],
   "source": [
    "# compile the model and check it \n",
    "optimizer = Adam(0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['categorical_accuracy', top_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A3E5saXh1Ozx",
    "outputId": "fa7584f3-5a9c-4789-f173-ad508e877278"
   },
   "outputs": [],
   "source": [
    "# always use earlystopping\n",
    "# the restore_best_weights parameter load the weights of the best iteration once the training finishes\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# checkpoint to save model\n",
    "chkpt = ModelCheckpoint(filepath=\"gdrive/My Drive/skin_cancer_data/skin_cancer_final.h5\", save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# reduce on plateau\n",
    "rp = ReduceLROnPlateau(min_lr=1e-5, patience=2, factor=0.5, mode=\"max\", monitor=\"val_categorical_accuracy\")\n",
    "\n",
    "# number of training and validation steps for training and validation\n",
    "all_train_images = len(glob.glob(\"data/train/**/*.jpg\"))\n",
    "all_valid_images = len(glob.glob(\"data/valid/**/*.jpg\"))\n",
    "\n",
    "nb_train_steps =  all_train_images // batch_size\n",
    "nb_valid_steps = all_valid_images // batch_size\n",
    "\n",
    "# number of epochs \n",
    "nb_epochs=100\n",
    "print(\"Number of training and validation steps: \", nb_train_steps, nb_valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "MWuN97E81T6Q",
    "outputId": "f8ce5d9c-b4d1-49bb-a733-78a885e36e77"
   },
   "outputs": [],
   "source": [
    "# train the model \n",
    "history1 = model.fit_generator(train_data_gen, \n",
    "                              epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps, \n",
    "                              validation_data=(valid_images, valid_labels_cat),#valid_data_gen,\n",
    "                              #validation_steps = nb_valid_steps,\n",
    "                              class_weight = class_weights,\n",
    "                              callbacks=[es,chkpt, rp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAO1LDTjFg2j"
   },
   "outputs": [],
   "source": [
    "# unfreeze some layers of base network for fine-tuning\n",
    "for layer in model.layers[-20:]:\n",
    "  layer.trainable =True\n",
    "\n",
    "# compile the model and check it \n",
    "optimizer = SGD(0.0001, decay=1e-6, nesterov=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['categorical_accuracy', top_2])\n",
    "\n",
    "# checkpoint to save model\n",
    "chkpt = ModelCheckpoint(filepath=\"gdrive/My Drive/skin_cancer_data/skin_cancer_final_fine_tuned.h5\", save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "5raJvh1CFznt",
    "outputId": "6931a463-d04e-4c86-f937-a7cc13d862c1"
   },
   "outputs": [],
   "source": [
    "# fine-tune our current model\n",
    "history2 = model.fit_generator(train_data_gen, \n",
    "                              epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps, \n",
    "                              validation_data=valid_data_gen,\n",
    "                              validation_steps = nb_valid_steps, \n",
    "                              callbacks=[es,chkpt, rp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZXMfF3I_1QC"
   },
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(\"gdrive/My Drive/skin_cancer_data/skin_cancer_final_fine_tuned.h5\")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "preds = model.predict(valid_images)\n",
    "preds = np.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "colab_type": "code",
    "id": "hpcVRAuoAGsS",
    "outputId": "6323b042-dd08-4486-8c0c-44f17999315b"
   },
   "outputs": [],
   "source": [
    "# Get the confusion matrix\n",
    "cm = confusion_matrix(y_true=valid_labels, y_pred=preds)\n",
    "print(cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\".0f\")\n",
    "\n",
    "# labels and title\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "\n",
    "# ticks\n",
    "ax.xaxis.set_ticklabels(list(class_indices.keys()))\n",
    "ax.yaxis.set_ticklabels(list(class_indices.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "SQhZopKu_nm8",
    "outputId": "12da5db0-39af-4b21-93ad-e034d86f7b2d"
   },
   "outputs": [],
   "source": [
    "# Generate a classification report\n",
    "cancer_report = classification_report(valid_labels, preds, target_names=list(class_indices.keys()))\n",
    "print(cancer_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueONcMOblLS2"
   },
   "outputs": [],
   "source": [
    "# save the model for future use\n",
    "model.save(\"gdrive/My Drive/skin_cancer_data/skin_cancer_best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSEP_H8Qmh8A"
   },
   "outputs": [],
   "source": [
    "# save the architecture as well for future use \n",
    "json_string = model.to_json()\n",
    "\n",
    "f = open(\"gdrive/My Drive/skin_cancer_data/skin_cancer_best_model_arch.json\", \"w\")\n",
    "json.dump(json_string, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "skin_cancer.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
